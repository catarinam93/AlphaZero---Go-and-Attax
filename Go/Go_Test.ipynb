{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64890a1-1a72-412b-a32c-701a5a557e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e630f036-9678-4290-8057-d243da38a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run NeuralNetwork_Go.ipynb # Neural Network\n",
    "%run GoGame.ipynb # Game\n",
    "%run MCTS_Go.ipynb # MCTS\n",
    "%run AlphaZero_Go.ipynb # Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6234c8-5e63-42f5-98d6-03c8756a032c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### To test only the game - Player vs Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2f9bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the dimension of the board: 7 - 7*7 or 9 - 9*9\n",
      "7\n",
      "Board State:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "valid moves [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 81]\n",
      "pass_count:  0\n",
      "Player 1's turn: 0\n",
      "Board State:\n",
      "[[1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "valid moves [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 81]\n",
      "pass_count:  0\n",
      "Player -1's turn: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ff6683e08743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mMAX_MOVE_TIME\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Wait for the player to make a move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get the current time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;31m# Calculate the elapsed time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnext_notification_time\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mnext_notification_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Check if it's time to notify the player\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to get a player's action from the input\n",
    "def get_player_action(player, valid_moves, action_queue, continue_waiting):\n",
    "    try: # Try to get a valid action from the player\n",
    "        while continue_waiting[0]: # Wait for the player to enter a valid action\n",
    "            print(f\"Player {player}'s turn: \", end=\"\", flush=True) # Flush the print buffer to ensure the prompt is displayed\n",
    "            action = input() # Get the player's input\n",
    "            if action: # Check if the input is not empty\n",
    "                action = int(action) # Convert the input to an integer\n",
    "                if action in valid_moves: # Check if the input is a valid move\n",
    "                    action_queue.append(action) # Add the action to the queue\n",
    "                    break # Exit the loop\n",
    "            time.sleep(0.5)  # Short sleep to prevent busy waiting\n",
    "    except ValueError: # Catch invalid input    \n",
    "        print(\"Invalid input, please enter a number.\") # Print an error message\n",
    "\n",
    "player = 1 # Player to start the game\n",
    "MAX_MOVE_TIME = 30  # Maximum time for a move in seconds\n",
    "\n",
    "# Main loop for the game\n",
    "while True: \n",
    "    print(\"Choose the dimension of the board: 7 - 7*7 or 9 - 9*9\") \n",
    "    dimension = int(input()) # Get the player's input\n",
    "    if dimension == 7 or dimension == 9: # Check if the input is a valid dimension\n",
    "        game = GoGame(dimension) # Initialize the game\n",
    "        state = game.get_initial_state() # Get the initial state\n",
    "\n",
    "        # Main loop for the game turns\n",
    "        while True:\n",
    "            print(\"Board State:\") \n",
    "            print(state) # Print the current state\n",
    "            valid_moves = game.get_valid_moves(state, player) # Get the valid moves for the current player\n",
    "            print(\"valid moves\", valid_moves) # Print the valid moves\n",
    "            print(\"pass_count: \", game.pass_count) # Print the number of consecutive passes\n",
    "\n",
    "            start_time = time.time()  # Start the move timer\n",
    "            action_queue = [] # Queue to store the player's action\n",
    "            continue_waiting = [True] # Flag to signal the input thread to continue waiting for input\n",
    "            input_thread = threading.Thread(target=get_player_action, args=(player, valid_moves, action_queue, continue_waiting)) # Create a thread to get the player's input\n",
    "            input_thread.start() # Start the thread\n",
    "\n",
    "            next_notification_time = MAX_MOVE_TIME # Time for the next notification\n",
    "             \n",
    "            while time.time() - start_time < MAX_MOVE_TIME: # Wait for the player to make a move\n",
    "                current_time = time.time() # Get the current time\n",
    "                elapsed_time = current_time - start_time # Calculate the elapsed time\n",
    "                if elapsed_time < next_notification_time and elapsed_time >= next_notification_time - 5: # Check if it's time to notify the player\n",
    "                    print(f\"Remaining time: {next_notification_time - elapsed_time:.2f} seconds\") # Print the remaining time\n",
    "                    next_notification_time -= 5 # Update the next notification time\n",
    "\n",
    "                if not input_thread.is_alive(): # Check if the input thread has finished\n",
    "                    break  # Exit the loop if the player has made a move\n",
    "\n",
    "            if input_thread.is_alive(): # Check if the input thread is still alive\n",
    "                continue_waiting[0] = False  # Signal the thread to stop waiting for input\n",
    "                input_thread.join()  # Ensure the thread completes\n",
    "                print(f\"Time's up! Switching to Player {-player}.\") # Print a message to notify the player\n",
    "                player = -player # Switch players\n",
    "                continue  # Skip to the next player without updating the state\n",
    "\n",
    "            if action_queue: # Check if the player has made a move\n",
    "                action = action_queue.pop(0) # Get the player's action\n",
    "                is_valid_move = game.is_valid_move(action, state, player) # Check if the action is valid\n",
    " \n",
    "                if not is_valid_move: # Check if the action is not valid\n",
    "                    print(\"Please select a valid move\") # Print an error message\n",
    "                    continue # Skip to the next player without updating the state\n",
    "\n",
    "                state = game.get_next_state(state, action, player) # Update the state\n",
    "                value, winner, is_terminal = game.get_value_and_terminated(state, action, player) # Check if the game has ended\n",
    "\n",
    "                if is_terminal: # Check if the game has ended\n",
    "                    print(state) # Print the final state\n",
    "                    if value == 1: # Check if someone won\n",
    "                        print(winner, \"won\") # Print a message to notify the player\n",
    "                    else: # It's a draw\n",
    "                        print(\"draw\") # Print a message to notify the player\n",
    "                    break # Exit the game loop\n",
    "\n",
    "            player = -player  # Switch players\n",
    "\n",
    "    else: # Invalid dimension \n",
    "        print(\"Select a valid dimension\") # Print an error message\n",
    "        continue # Skip to the next player without updating the state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b82085",
   "metadata": {},
   "source": [
    "### To test the game with MCTS - Player vs MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1a82e-58c4-4384-9b88-66cf3eccd8f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### To test the nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f016ee",
   "metadata": {},
   "source": [
    "If you want to test the RNN, change model to : GoRNN(game, 4, 64, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11471b94-152a-4925-9d7c-a1ed7b69b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking liberties for stone at (0, 2)\n",
      "Captured stones: []\n",
      "Applying move at row 0, column 2 by player 1\n",
      "Checking liberties for stone at (0, 7)\n",
      "Captured stones: []\n",
      "Applying move at row 0, column 7 by player -1\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "value:  0.6140791177749634\n",
      "policy:  [0.00713453 0.00838346 0.01012406 0.01091435 0.01987647 0.0104742\n",
      " 0.00563766 0.01291399 0.014367   0.01699454 0.01613341 0.01640244\n",
      " 0.01263381 0.00842671 0.00739302 0.01019303 0.00911524 0.00847856\n",
      " 0.01223416 0.00787089 0.01733544 0.01334654 0.01082395 0.02092378\n",
      " 0.01527335 0.0194874  0.02424977 0.01071509 0.00897275 0.00851602\n",
      " 0.01360789 0.00981062 0.014978   0.00996742 0.00892945 0.01460547\n",
      " 0.00662968 0.01595523 0.01814751 0.0108945  0.00852854 0.00731383\n",
      " 0.01317086 0.00906067 0.01168495 0.0170798  0.01442438 0.01780712\n",
      " 0.0114959  0.00744785 0.00634231 0.01109006 0.00819301 0.01699235\n",
      " 0.00807649 0.00806131 0.01504926 0.01096932 0.006521   0.00594428\n",
      " 0.01230594 0.03081824 0.0106898  0.01180643 0.01217682 0.00828022\n",
      " 0.00987161 0.01760811 0.01618744 0.01085373 0.0078051  0.01421978\n",
      " 0.00614369 0.00939598 0.00894003 0.0164177  0.00703718 0.02347038\n",
      " 0.01300295 0.00473185 0.02026737 0.01384499]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "game = GoGame(9) # 9 - dimension\n",
    "state = game.get_initial_state() # Get the initial state\n",
    "state = game.get_next_state(state, 2, 1) # 2 - action, 1 - player\n",
    "state = game.get_next_state(state, 7, -1) # 7 - action, -1 - player\n",
    "\n",
    "encoded_state = game.get_encoded_state(state)  # Get the encoded state\n",
    "print(encoded_state) # Print the encoded state\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check if GPU is available\n",
    "\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0) # Convert the encoded state to a tensor and add a batch dimension (batch size = 1)\n",
    "model = ResNet(game, 4, 64, device) # Initialize the model with the same parameters used in training (4 residual blocks, 64 filters)\n",
    "print(tensor_state) # Print the tensor state\n",
    "policy, value= model(tensor_state) # Get the policy and value predictions\n",
    "value = value.item() # Get the value as a scalar\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy() # Convert the policy to a numpy array\n",
    "print(\"value: \", value) # Print the value\n",
    "np.set_printoptions(threshold=np.inf) # Print the full policy array\n",
    "print(\"policy: \", policy) # Print the policy\n",
    "\n",
    "plt.bar(range(game.action_size+1), policy) # Plot the policy\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b21a4-21fe-4845-a25a-5b35c945592d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### To test the game with MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5103273-d0a2-4ec3-84da-f95d5c70e5d8",
   "metadata": {},
   "source": [
    "For this one you need to uncomment the version of MCTS commented on MCTS_Go.ipynb\n",
    "\n",
    "Do not forget to comment the current version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fc739-4004-4823-8fc2-8f0a10c55f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = GoGame(9) # 9 - dimension\n",
    "player = 1 # Player to start the game\n",
    "state = game.get_initial_state() # Get the initial state\n",
    "\n",
    "args = {\n",
    "    'C' : 1.41,  # Exploration constant for the UCT formula \n",
    "    'num_searches': 5 # Number of searches to run for each move\n",
    "}\n",
    "    \n",
    "mcts = MCTS(game, args, player) # Initialize the MCTS\n",
    "\n",
    "# Main loop for the game\n",
    "while True: \n",
    "    \n",
    "    game.reset_time() # Reset the game time\n",
    "    \n",
    "    if player == 1: # Check if it's the player's turn\n",
    "        print(\"Board State:\") \n",
    "        print(state) # Print the current state\n",
    "        valid_moves = game.get_valid_moves(state, player) # Get the valid moves for the current player\n",
    "        print(\"valid moves\", valid_moves) # Print the valid moves\n",
    "        \n",
    "        print(\"If you would like to pass, select 81 otherwise choose the cell you want\") \n",
    "        action = int(input(f\"{player}: \")) # Get the player's input\n",
    "        \n",
    "        is_valid_move = game.is_valid_move(action, state, player) # Check if the action is valid\n",
    "        \n",
    "        if not is_valid_move: # Check if the action is not valid\n",
    "            print(\"Please select a valid move\") # Print an error message\n",
    "            continue \n",
    "        else: # Valid move\n",
    "            state = game.get_next_state(state, action, player) # Update the state\n",
    "            value, winner, is_terminal = game.get_value_and_terminated(state, action, player) # Check if the game has ended\n",
    "\n",
    "    else: # AI's turn\n",
    "        # neutral_state = game.change_perspective(state, player) # Change the perspective of the state\n",
    "        mcts_probs = mcts.search(state) # Get the MCTS probabilities\n",
    "        action = np.argmax(mcts_probs) # Get the action with the highest probability\n",
    "\n",
    "        state = game.get_next_state(state, action, player) # Update the state\n",
    "        value, winner, is_terminal = game.get_value_and_terminated(state, action, player) # Check if the game has ended\n",
    "    \n",
    "    if action == 81: # Check if the player passed\n",
    "        game.pass_count += 1 # Increment the number of consecutive passes\n",
    "\n",
    "    if is_terminal: # Check if the game has ended\n",
    "        if value == 1: # Check if someone won\n",
    "            print(winner, \"won\") # Print a message to notify the player\n",
    "        else: # It's a draw\n",
    "            print(\"draw\") # Print a message to notify the player\n",
    "        break\n",
    "    \n",
    "    player = -player # Switch players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98676263-d14d-4085-9492-da162e140d43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### To test the game with the nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "657b42df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the dimension of the board: 7 - 7*7 or 9 - 9*9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-86a00a7f2d78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Choose the dimension of the board\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Choose the dimension of the board: 7 - 7*7 or 9 - 9*9\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdimension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdimension\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Select a valid dimension\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             )\n\u001b[1;32m--> 848\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Function to get a player's action from the input\n",
    "def get_player_action(player, valid_moves, action_queue):\n",
    "    try:\n",
    "        print(f\"Player {player}'s turn: \", end=\"\", flush=True)\n",
    "        action = input()\n",
    "        if action:\n",
    "            action = int(action)\n",
    "            if action in valid_moves:\n",
    "                action_queue.append(action)\n",
    "    except ValueError:\n",
    "        print(\"Invalid input, please enter a number.\")\n",
    "\n",
    "# Function for AI to make a move using MCTS\n",
    "def get_ai_action(mcts, state):\n",
    "    mcts_probs = mcts.search(state)\n",
    "    action = np.argmax(mcts_probs)\n",
    "    return action\n",
    "\n",
    "# Choose the dimension of the board\n",
    "print(\"Choose the dimension of the board: 7 - 7*7 or 9 - 9*9\") \n",
    "dimension = int(input())\n",
    "if dimension not in [7, 9]:\n",
    "    print(\"Select a valid dimension\")\n",
    "    # Exit or restart the loop\n",
    "else:\n",
    "    game = GoGame(dimension)\n",
    "    state = game.get_initial_state()\n",
    "    \n",
    "    # MCTS arguments\n",
    "    args = {\n",
    "        'C': 2,  # Exploration constant\n",
    "        'num_searches': 10  # Number of searches per move\n",
    "    }\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check if GPU is available\n",
    "\n",
    "    # Initialize MCTS for the AI player\n",
    "    model = ResNet(game, 4, 64, device)\n",
    "    model.eval()\n",
    "    mcts = MCTS(game, args, -1, model)  # Assuming AI is player -1\n",
    "\n",
    "    player = 1  # Human player starts\n",
    "\n",
    "    # Game loop\n",
    "    while True:\n",
    "        print(\"Board State:\")\n",
    "        print(state)\n",
    "        valid_moves = game.get_valid_moves(state, player)\n",
    "        print(\"valid moves\", valid_moves)\n",
    "\n",
    "        if player == 1:  # Human player\n",
    "            action_queue = []\n",
    "            get_player_action(player, valid_moves, action_queue)\n",
    "            action = action_queue.pop(0) if action_queue else 81  # Default to pass if no input\n",
    "\n",
    "        else:  # AI player\n",
    "            action = get_ai_action(mcts, state)\n",
    "\n",
    "        # Update the game state\n",
    "        state = game.get_next_state(state, action, player)\n",
    "        value, winner, is_terminal = game.get_value_and_terminated(state, action, player)\n",
    "\n",
    "        if is_terminal:\n",
    "            print(state)\n",
    "            if value == 1:\n",
    "                print(winner, \"won\")\n",
    "            else:\n",
    "                print(\"draw\")\n",
    "            break\n",
    "\n",
    "        player = -player  # Switch players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45c5937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MCTS\n",
      "valid moves [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
      "If you would like to pass, select 81 otherwise choose the cell you want\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e76873686be9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If you would like to pass, select 81 otherwise choose the cell you want\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Player {player}: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Get player's action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Check if the action is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             )\n\u001b[1;32m--> 848\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "## game = GoGame(9) # 9 - dimension\n",
    "\n",
    "player = 1 # Player to start the game\n",
    "state = game.get_initial_state() # Get the initial state\n",
    "\n",
    "args = {\n",
    "    'C' : 2,  # Exploration constant for the UCT formula\n",
    "    'num_searches': 10 # Number of searches to run for each move\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check if GPU is available\n",
    "\n",
    "model = ResNet(game, 4, 64, device) # Initialize the model with the same parameters used in training (4 residual blocks, 64 filters)\n",
    "model.eval() # Set the model to evaluation mode\n",
    "mcts = MCTS(game, args, -1, model) # Initialize the MCTS\n",
    "\n",
    "# Main loop for the game\n",
    "while True:\n",
    "    game.reset_time() # Reset the game time\n",
    "    \n",
    "    if player == 1: # Check if it's the player's turn    \n",
    "         \n",
    "        valid_moves = game.get_valid_moves(state, player)  # Get valid moves\n",
    "        print(\"valid moves\", valid_moves)\n",
    "\n",
    "        print(\"If you would like to pass, select 81 otherwise choose the cell you want\")\n",
    "        action = int(input(f\"Player {player}: \"))  # Get player's action\n",
    "\n",
    "        if action in valid_moves:  # Check if the action is valid\n",
    "            state = game.get_next_state(state, action, player)  # Update the state\n",
    "            print(\"Board State after your move:\")\n",
    "            print(state)\n",
    "        else:\n",
    "            print(\"Invalid move, please select a valid move\")\n",
    "            continue  # Skip the rest of the loop and prompt for move again\n",
    "            \n",
    "\n",
    "    else: # AI's turn\n",
    "        neutral_state = game.change_perspective(state, player) # Change the perspective of the state\n",
    "\n",
    "        mcts_probs = mcts.search(neutral_state) # Get the MCTS probabilities\n",
    "        action = np.argmax(mcts_probs) # Get the action with the highest probability\n",
    "\n",
    "        state = game.get_next_state(state, action, player) # Update the state\n",
    "     \n",
    "    print(\"Board State:\") \n",
    "    print(state) # Print the current state\n",
    "    value, winner, is_terminal = game.get_value_and_terminated(state, action, player) # Check if the game has ended\n",
    "    \n",
    "    if action == 81: # Check if the player passed\n",
    "        game.pass_count += 1 # Increment the number of consecutive passes\n",
    "\n",
    "    if is_terminal: # Check if the game has ended\n",
    "        if value == 1: # Check if someone won\n",
    "            print(winner, \"won\") # Print a message to notify the player\n",
    "        else: # It's a draw\n",
    "            print(\"draw\") # Print a message to notify the player\n",
    "        break\n",
    "    \n",
    "    player = -player # Switch players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb5810-4519-45d1-b850-f342529f16be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### To train with the AlphaZero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fbac0c-cef9-4440-9f8f-102e18bd6787",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Board Dimension = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d08b1c-1f34-47c1-8436-e422fdeeabe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MCTS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c531825f894bc392e522d81b8ca725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MCTS\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2592 and 1568x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m\n\u001b[0;32m     18\u001b[0m args \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# Exploration constant for the UCT formula\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_searches\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;66;03m# Number of searches to run for each move\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.3\u001b[39m \u001b[38;5;66;03m# Weight of the value loss in the total loss\u001b[39;00m\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     29\u001b[0m alphaZero \u001b[38;5;241m=\u001b[39m AlphaZero(model, optimizer, game, args) \u001b[38;5;66;03m# Initialize the AlphaZero object\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m alphaZero\u001b[38;5;241m.\u001b[39mlearn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\3424603522.py:165\u001b[0m, in \u001b[0;36mAlphaZero.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_selfPlay_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m]): \u001b[38;5;66;03m# For each iteration of self-play\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     game_memory, game_outcome, game_length, top_move_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselfPlay() \u001b[38;5;66;03m# Play a game of self-play\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     memory \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m game_memory \u001b[38;5;66;03m# Append the game memory to the memory list\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     outcomes\u001b[38;5;241m.\u001b[39mappend(game_outcome) \u001b[38;5;66;03m# Append the outcome of the game\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\3424603522.py:39\u001b[0m, in \u001b[0;36mAlphaZero.selfPlay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     neutral_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mchange_perspective(state, player)\n\u001b[1;32m---> 39\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcts\u001b[38;5;241m.\u001b[39msearch(neutral_state)\n\u001b[0;32m     41\u001b[0m     valid_moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_valid_moves(state, player)\n\u001b[0;32m     42\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m [prob \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m valid_moves \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(action_probs)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\2068707938.py:130\u001b[0m, in \u001b[0;36mMCTS.search\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Check if the node is terminate and backpropagate immediately if not we expand and simulate\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_terminal: \n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# Expansion phase\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     policy, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    131\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_encoded_state(node\u001b[38;5;241m.\u001b[39mstate))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Unsqueeze to add a batch dimension\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Expand the node with the policy and simulate\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     policy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(policy, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# Softmax the policy and convert it to a numpy array\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\2835086749.py:48\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resBlock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackBone: \n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m resBlock(x) \n\u001b[1;32m---> 48\u001b[0m policy_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicyHead(x) \u001b[38;5;66;03m# Raw policy logits\u001b[39;00m\n\u001b[0;32m     49\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalueHead(x) \u001b[38;5;66;03m# Value head for predicting the state value\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Normalize policy logits to probabilities\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2592 and 1568x50)"
     ]
    }
   ],
   "source": [
    "game = GoGame(7) # 7 - dimension\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check if GPU is available\n",
    "\n",
    "state = game.get_initial_state() # Get the initial state\n",
    "\n",
    "input_size = 7 * 7 # Grid size\n",
    "hidden_size = 128 # Size of the hidden layer in the RNN\n",
    "num_layers = 2 # Number of layers in the RNN\n",
    "policy_size = game.action_size # Number of possible actions\n",
    "value_size = 1 # Size of the value output\n",
    "model = ResNet(game, 4, 64, device) # Initialize the model\n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001) # Initialize the optimizer with weight decay to prevent overfitting (L2 regularization) \n",
    "\n",
    "# Training parameters\n",
    "args = { \n",
    "    'C': 2, # Exploration constant for the UCT formula\n",
    "    'num_searches': 3, # Number of searches to run for each move\n",
    "    'num_iterations': 3, # Number of iterations to run the training loop\n",
    "    'num_selfPlay_iterations': 20, # Number of self-play games to play in each iteration\n",
    "    'num_epochs': 4, # Number of epochs to train the model\n",
    "    'batch_size': 128, # Batch size for training\n",
    "    'epsilon': 0.25, # Fraction of random moves to play during self-play\n",
    "    'alpha': 0.3 # Weight of the value loss in the total loss\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, game, args) # Initialize the AlphaZero object\n",
    "alphaZero.learn() # Run the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14472779-9101-435a-8672-592b4e9bc558",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Board Dimension = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabfc713-87d6-4c0f-a53a-4934d3fdfc61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MCTS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bcbb6be53b4d4594a0e920a8cfb4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MCTS\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# Exploration constant for the UCT formula\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_searches\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;66;03m# Number of searches to run for each move\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.3\u001b[39m \u001b[38;5;66;03m# Weight of the value loss in the total loss\u001b[39;00m\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m alphaZero \u001b[38;5;241m=\u001b[39m AlphaZero(model, optimizer, game, args) \u001b[38;5;66;03m# Initialize the AlphaZero object\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m alphaZero\u001b[38;5;241m.\u001b[39mlearn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\3424603522.py:165\u001b[0m, in \u001b[0;36mAlphaZero.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_selfPlay_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m]): \u001b[38;5;66;03m# For each iteration of self-play\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     game_memory, game_outcome, game_length, top_move_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselfPlay() \u001b[38;5;66;03m# Play a game of self-play\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     memory \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m game_memory \u001b[38;5;66;03m# Append the game memory to the memory list\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     outcomes\u001b[38;5;241m.\u001b[39mappend(game_outcome) \u001b[38;5;66;03m# Append the outcome of the game\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\3424603522.py:39\u001b[0m, in \u001b[0;36mAlphaZero.selfPlay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     neutral_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mchange_perspective(state, player)\n\u001b[1;32m---> 39\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcts\u001b[38;5;241m.\u001b[39msearch(neutral_state)\n\u001b[0;32m     41\u001b[0m     valid_moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_valid_moves(state, player)\n\u001b[0;32m     42\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m [prob \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m valid_moves \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(action_probs)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23152\\2068707938.py:131\u001b[0m, in \u001b[0;36mMCTS.search\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Check if the node is terminate and backpropagate immediately if not we expand and simulate\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_terminal: \n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# Expansion phase\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     policy, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m--> 131\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_encoded_state(node\u001b[38;5;241m.\u001b[39mstate))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Unsqueeze to add a batch dimension\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Expand the node with the policy and simulate\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     policy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(policy, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# Softmax the policy and convert it to a numpy array\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "game = GoGame(9) # 9 - dimension\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check if GPU is available\n",
    "\n",
    "state = game.get_initial_state() # Get the initial state\n",
    "\n",
    "model = ResNet(game, 4, 64, device) # Initialize the model\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001) # Initialize the optimizer with weight decay to prevent overfitting (L2 regularization)\n",
    "\n",
    "# Training parameters\n",
    "args = {\n",
    "    'C': 2, # Exploration constant for the UCT formula\n",
    "    'num_searches': 3, # Number of searches to run for each move\n",
    "    'num_iterations': 3, # Number of iterations to run the training loop\n",
    "    'num_selfPlay_iterations': 5, # Number of self-play games to play in each iteration\n",
    "    'num_epochs': 4, # Number of epochs to train the model\n",
    "    'batch_size': 64, # Batch size for training\n",
    "    'epsilon': 0.25, # Fraction of random moves to play during self-play\n",
    "    'alpha': 0.3 # Weight of the value loss in the total loss\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, game, args) # Initialize the AlphaZero object\n",
    "alphaZero.learn() # Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2b326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
